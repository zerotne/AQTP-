DATA:
  MAX_SAMPLE_INTERVAL: 400
  MEAN:
  - 0.485
  - 0.456
  - 0.406
  SEARCH:
    CENTER_JITTER: 4.5
    FACTOR: 4.5
    NUMBER: 4
    SCALE_JITTER: 0.5
    SIZE: 384
  STD:
  - 0.229
  - 0.224
  - 0.225
  TEMPLATE:
    CENTER_JITTER: 0
    FACTOR: 2.0
    SCALE_JITTER: 0
    SIZE: 192
  TRAIN:
    DATASETS_NAME:
    - TNL2K_Lang
    - LASOT_Lang
    - RefCOCO14
    - OTB_Lang
    DATASETS_RATIO:
    - 6
    - 6
    - 6
    - 1
    SAMPLE_PER_EPOCH: 15000
  VAL:
    DATASETS_NAME:
    - GOT10K_votval
    DATASETS_RATIO:
    - 1
    SAMPLE_PER_EPOCH: 10000
MODEL:
  BACKBONE:
    STRIDE: 16
    TYPE: hivit_base
    Z_SIZE: 192
    X_SIZE: 384
  EXTRA_MERGER: false
  HEAD:
    NUM_CHANNELS: 256
    TYPE: CENTER
  PRETRAIN_FILE: mae_hivit_base_1600ep.pth
  RETURN_INTER: false
  TRANSFORMER_DEC:
    DEC_LAYERS: 3
    DIM_FEEDFORWARD: 512
    DROPOUT: 0.1
    ENC_LAYERS: 0
    NHEADS: 8
  TARGET_QUERY_PROMPTS:
    PROMPT_LAYERS: 8
    NHEADS: 8
    DROPOUT: 0.1
  TEXT_ENCODER: roberta-base  # choose between roberta-base, bert-base, clip
  FREEZE_TEXT_ENCODER: True
  VLFUSION_LAYERS: 1       # multi-modal encoder layers

TEST:
  EPOCH: 150
  SEARCH_FACTOR: 4.5
  SEARCH_SIZE: 384
  TEMPLATE_FACTOR: 2.0
  TEMPLATE_SIZE: 192
TRAIN:
  AMP: false
  BACKBONE_MULTIPLIER: 0.1
  BATCH_SIZE: 4  #4
  DROP_PATH_RATE: 0.1
  EPOCH: 150
  GIOU_WEIGHT: 2.0
  GRAD_CLIP_NORM: 0.1
  L1_WEIGHT: 5.0
  QUERY_AUX_WEIGHT: 0.1
  LR: 0.0001  #0.0002
  LR_DROP_EPOCH: 120
  NUM_WORKER: 5
  OPTIMIZER: ADAMW
  PRINT_INTERVAL: 50
  SCHEDULER:
    DECAY_RATE: 0.1
    TYPE: step
  VAL_EPOCH_INTERVAL: 1000
  WEIGHT_DECAY: 0.0001
